{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c877a362",
   "metadata": {},
   "source": [
    "## Helper Methods\n",
    "- Tools we may use later for data pre-processing and graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5908f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Flatten, Conv2D, MaxPooling2D, concatenate, Lambda, BatchNormalization, Activation\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_curve, auc, mean_squared_error\n",
    "import matplotlib.pyplot as plt \n",
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_preproc\n",
    "\n",
    "\n",
    "#import repeats becuase something is missing\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort = True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by = ['y'],inplace = True)\n",
    "    a = plt.plot(t['pred'].tolist(), ls = '', marker='s', markersize = 1.0, label = 'prediction', color = 'orange')\n",
    "    b = plt.plot(t['y'].tolist(), label = 'expected', color = 'blue')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n",
    "def plot_confusion_matrix(cm, names, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(names))\n",
    "    plt.xticks(tick_marks, names, rotation=45)\n",
    "    plt.yticks(tick_marks, names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "# Plot an ROC. pred - the predictions, y - the expected output.\n",
    "def plot_roc(pred,y, file_path):\n",
    "    fpr, tpr, thresholds = roc_curve(y, pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC)')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig(file_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "fa6681a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "def plot_losses(history, base_path, iteration:int):\n",
    "    # Plot training & validation loss over epochs\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.ylim(bottom=0.0, top=1.0)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Training vs. Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\n",
    "        os.path.join(base_path, f\"training-validiation-loss--epoch---Model {iteration}\")\n",
    "    )\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def print_schema(dataframe: pd.DataFrame):\n",
    "    print('~~~~~~dataframe schema~~~~~~')\n",
    "    print(f\"Dataframe shape: {dataframe.shape} | Dataframe length: {len(dataframe)}\")\n",
    "    print('Column labels: ')\n",
    "    print(dataframe.columns)\n",
    "    print('Dataframe head: ')\n",
    "    print(f\"{dataframe.head()}\")\n",
    "def print_column(dataframe: pd.DataFrame, columns: str | list[str]):\n",
    "    if isinstance(columns, list):\n",
    "        for i, label in enumerate(columns):\n",
    "            print(f\"column {i}\")\n",
    "            print(dataframe[label])\n",
    "    else:\n",
    "        print(dataframe[columns])\n",
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)\n",
    "def encode_text_dummy(df, name):\n",
    "    dummies = pd.get_dummies(df[name])\n",
    "    for x in dummies.columns:\n",
    "        dummy_name = \"{}-{}\".format(name, x)\n",
    "        df[dummy_name] = dummies[x]\n",
    "    df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).\n",
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "\n",
    "# Encode a numeric column as zscores\n",
    "def encode_numeric_zscore(df, name, mean=None, sd=None):\n",
    "    if mean is None:\n",
    "        mean = df[name].mean()\n",
    "\n",
    "    if sd is None:\n",
    "        sd = df[name].std()\n",
    "\n",
    "    df[name] = (df[name] - mean) / sd\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the median\n",
    "def missing_median(df, name):\n",
    "    med = df[name].median()\n",
    "    df[name] = df[name].fillna(med)\n",
    "\n",
    "\n",
    "# Convert all missing values in the specified column to the default\n",
    "def missing_default(df, name, default_value):\n",
    "    df[name] = df[name].fillna(default_value)\n",
    "\n",
    "\n",
    "# Convert a Pandas dataframe to the x,y inputs that TensorFlow needs\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column. \n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if isinstance(target_type, Sequence) else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df[result].values.astype(np.float32), dummies.values.astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df[result].values.astype(np.float32), df[target].values.astype(np.float32)\n",
    "\n",
    "# Nicely formatted time string\n",
    "def hms_string(sec_elapsed):\n",
    "    h = int(sec_elapsed / (60 * 60))\n",
    "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
    "    s = sec_elapsed % 60\n",
    "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)\n",
    "\n",
    "\n",
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Remove all rows where the specified column is +/- sd standard deviations\n",
    "def remove_outliers(df, name, sd):\n",
    "    drop_rows = df.index[(np.abs(df[name] - df[name].mean()) >= (sd * df[name].std()))]\n",
    "    df.drop(drop_rows, axis=0, inplace=True)\n",
    "\n",
    "\n",
    "# Encode a column to a range between normalized_low and normalized_high.\n",
    "def encode_numeric_range(df, name, normalized_low=-1, normalized_high=1,\n",
    "                         data_low=None, data_high=None):\n",
    "    if data_low is None:\n",
    "        data_low = min(df[name])\n",
    "        data_high = max(df[name])\n",
    "\n",
    "    df[name] = ((df[name] - data_low) / (data_high - data_low)) \\\n",
    "               * (normalized_high - normalized_low) + normalized_low\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50a2d5",
   "metadata": {},
   "source": [
    "## Set up Environment\n",
    "Create test output folders and define paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "706beebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probably safe to ignore the following error: \n",
      "[Errno 17] File exists: '/Users/nyess/Desktop/VSCode/Python/Assignment4/bchurch2-Time-Series-Forecasting/test-output/'\n",
      "[Errno 17] File exists: '/Users/nyess/Desktop/VSCode/Python/Assignment4/bchurch2-Time-Series-Forecasting/test-output/iteration-1'\n",
      "Exiting to protect previous work.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "base_path=os.path.join(os.getcwd(), 'test-output/')\n",
    "\n",
    "iteration='iteration-1'\n",
    "full_path = os.path.join(base_path, iteration)\n",
    "try:\n",
    "        os.mkdir(base_path)\n",
    "except Exception as e:\n",
    "     print(f\"Probably safe to ignore the following error: \\n{e}\")\n",
    "\n",
    "try:\n",
    "    os.mkdir(full_path)\n",
    "except Exception as e:\n",
    "    print(f\"{e}\\nExiting to protect previous work.\")\n",
    "    sys.exit(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e712d9a2",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "c6f0b07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset and format\n",
    "TXT_DATASET_LOCATION = \"./business-dataset/AAPL.csv\"\n",
    "df = pd.read_csv(TXT_DATASET_LOCATION)\n",
    "\n",
    "#drop extra columns, reorder\n",
    "df.drop(['Date','Adj Close'], axis=1, inplace=True)\n",
    "df = df[[\"Open\",\"High\",\"Low\",\"Volume\",\"Close\"]]\n",
    "\n",
    "#remove NaN values\n",
    "df = df.dropna() \n",
    "\n",
    "#keep copy before normalization\n",
    "close_unnormalized = df['Close'].values.copy()\n",
    "\n",
    "#reset index after dropping rows\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "#normalize data (separate from close_unnormalized)\n",
    "for col in df.columns:\n",
    "    encode_numeric_zscore(df, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8e73a7",
   "metadata": {},
   "source": [
    "## Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "a9f9059f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom function for sliding window x/y data split\n",
    "def create_sliding_window_data(df, close_unnormalized, window_size):\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(window_size, len(df)):\n",
    "        #get window_size days of data (rows i-window_size to i-1)\n",
    "        window = df.iloc[i-window_size:i].values\n",
    "        x.append(window.flatten())\n",
    "        y.append(close_unnormalized[i])\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "05019fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XY split\n",
    "x, y = create_sliding_window_data(df, close_unnormalized, window_size=7)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8843fdba",
   "metadata": {},
   "source": [
    "## Model Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fc8727e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/keras/src/layers/core/dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2594.6404 - val_loss: 2572.1929\n",
      "Epoch 2/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - loss: 2328.9673 - val_loss: 2194.8843\n",
      "Epoch 3/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - loss: 1859.2900 - val_loss: 1555.4796\n",
      "Epoch 4/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - loss: 1170.6422 - val_loss: 750.6180\n",
      "Epoch 5/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 510.6255 - val_loss: 185.5864\n",
      "Epoch 6/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 732us/step - loss: 190.4232 - val_loss: 64.6114\n",
      "Epoch 7/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 146.7988 - val_loss: 53.4890\n",
      "Epoch 8/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 151.5572 - val_loss: 49.4141\n",
      "Epoch 9/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 139.9474 - val_loss: 46.5650\n",
      "Epoch 10/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - loss: 131.4647 - val_loss: 44.5126\n",
      "Epoch 11/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - loss: 130.8751 - val_loss: 44.3878\n",
      "Epoch 12/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step - loss: 132.6876 - val_loss: 41.9812\n",
      "Epoch 13/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - loss: 131.3266 - val_loss: 41.0307\n",
      "Epoch 14/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 119.9389 - val_loss: 38.7545\n",
      "Epoch 15/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - loss: 126.5529 - val_loss: 37.9643\n",
      "Epoch 16/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - loss: 111.1680 - val_loss: 36.9073\n",
      "Epoch 17/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - loss: 114.9203 - val_loss: 35.2419\n",
      "Epoch 18/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 117.5365 - val_loss: 35.6383\n",
      "Epoch 19/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - loss: 105.8597 - val_loss: 33.2162\n",
      "Epoch 20/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - loss: 111.5004 - val_loss: 34.2301\n",
      "Epoch 21/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 111.3282 - val_loss: 33.4569\n",
      "Epoch 22/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 104.5594 - val_loss: 30.4898\n",
      "Epoch 23/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 103.7701 - val_loss: 29.7554\n",
      "Epoch 24/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 107.8928 - val_loss: 29.2264\n",
      "Epoch 25/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 103.8299 - val_loss: 27.8464\n",
      "Epoch 26/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 98.2273 - val_loss: 27.3909\n",
      "Epoch 27/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 604us/step - loss: 101.8687 - val_loss: 28.6343\n",
      "Epoch 28/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - loss: 96.5252 - val_loss: 26.3408\n",
      "Epoch 29/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - loss: 92.1684 - val_loss: 25.6110\n",
      "Epoch 30/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 99.9174 - val_loss: 24.3179\n",
      "Epoch 31/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - loss: 91.4490 - val_loss: 23.5931\n",
      "Epoch 32/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 90.7915 - val_loss: 23.1239\n",
      "Epoch 33/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 87.3303 - val_loss: 21.7120\n",
      "Epoch 34/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586us/step - loss: 87.6123 - val_loss: 21.7911\n",
      "Epoch 35/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - loss: 87.2850 - val_loss: 20.2999\n",
      "Epoch 36/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - loss: 90.0443 - val_loss: 20.0065\n",
      "Epoch 37/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 581us/step - loss: 82.4960 - val_loss: 20.0154\n",
      "Epoch 38/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - loss: 83.7343 - val_loss: 19.3808\n",
      "Epoch 39/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 83.1593 - val_loss: 19.6095\n",
      "Epoch 40/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 83.5296 - val_loss: 19.2098\n",
      "Epoch 41/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 79.5387 - val_loss: 17.6888\n",
      "Epoch 42/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - loss: 81.4499 - val_loss: 17.1759\n",
      "Epoch 43/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 80.4261 - val_loss: 15.9933\n",
      "Epoch 44/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 81.3514 - val_loss: 15.9833\n",
      "Epoch 45/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 75.9326 - val_loss: 15.2523\n",
      "Epoch 46/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 77.4030 - val_loss: 13.9813\n",
      "Epoch 47/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 578us/step - loss: 69.8477 - val_loss: 14.7166\n",
      "Epoch 48/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 621us/step - loss: 74.6072 - val_loss: 16.1595\n",
      "Epoch 49/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 71.2677 - val_loss: 12.5666\n",
      "Epoch 50/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 71.2858 - val_loss: 15.2831\n",
      "Epoch 51/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 71.2232 - val_loss: 11.6301\n",
      "Epoch 52/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - loss: 65.5521 - val_loss: 11.0322\n",
      "Epoch 53/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - loss: 73.1482 - val_loss: 12.5779\n",
      "Epoch 54/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 66.7097 - val_loss: 10.5418\n",
      "Epoch 55/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - loss: 65.1382 - val_loss: 9.8714\n",
      "Epoch 56/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 68.6769 - val_loss: 10.3906\n",
      "Epoch 57/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - loss: 71.5526 - val_loss: 9.7416\n",
      "Epoch 58/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - loss: 71.0038 - val_loss: 8.6250\n",
      "Epoch 59/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - loss: 68.0384 - val_loss: 8.5718\n",
      "Epoch 60/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 68.3672 - val_loss: 8.0222\n",
      "Epoch 61/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 619us/step - loss: 65.6154 - val_loss: 8.4630\n",
      "Epoch 62/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - loss: 65.1025 - val_loss: 7.4493\n",
      "Epoch 63/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - loss: 66.4491 - val_loss: 7.2964\n",
      "Epoch 64/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - loss: 68.2926 - val_loss: 9.3023\n",
      "Epoch 65/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - loss: 64.2689 - val_loss: 7.3349\n",
      "Epoch 66/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 60.7957 - val_loss: 6.3042\n",
      "Epoch 67/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - loss: 65.6696 - val_loss: 6.2993\n",
      "Epoch 68/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - loss: 64.2713 - val_loss: 6.3642\n",
      "Epoch 69/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - loss: 61.5216 - val_loss: 8.1994\n",
      "Epoch 70/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - loss: 56.9285 - val_loss: 6.2268\n",
      "Epoch 71/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - loss: 58.7287 - val_loss: 5.8468\n",
      "Epoch 72/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 60.3646 - val_loss: 6.8944\n",
      "Epoch 73/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - loss: 61.5029 - val_loss: 4.8614\n",
      "Epoch 74/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - loss: 57.5862 - val_loss: 4.6577\n",
      "Epoch 75/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - loss: 61.4918 - val_loss: 4.6756\n",
      "Epoch 76/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 61.1086 - val_loss: 4.5128\n",
      "Epoch 77/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 591us/step - loss: 58.4513 - val_loss: 4.7686\n",
      "Epoch 78/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - loss: 55.3268 - val_loss: 5.0935\n",
      "Epoch 79/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603us/step - loss: 57.0432 - val_loss: 6.2590\n",
      "Epoch 80/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - loss: 56.9347 - val_loss: 4.2498\n",
      "Epoch 81/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 57.0482 - val_loss: 5.0494\n",
      "Epoch 82/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 623us/step - loss: 55.3395 - val_loss: 4.5538\n",
      "Epoch 83/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - loss: 57.5536 - val_loss: 3.8149\n",
      "Epoch 84/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - loss: 60.1839 - val_loss: 5.8628\n",
      "Epoch 85/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - loss: 57.5743 - val_loss: 4.9668\n",
      "Epoch 86/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 56.9182 - val_loss: 4.9863\n",
      "Epoch 87/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - loss: 57.3809 - val_loss: 3.6844\n",
      "Epoch 88/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - loss: 52.6156 - val_loss: 3.9113\n",
      "Epoch 89/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - loss: 53.2065 - val_loss: 3.6580\n",
      "Epoch 90/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 572us/step - loss: 58.5114 - val_loss: 3.8030\n",
      "Epoch 91/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 617us/step - loss: 56.7386 - val_loss: 4.6670\n",
      "Epoch 92/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 56.7868 - val_loss: 3.4428\n",
      "Epoch 93/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 56.4681 - val_loss: 3.5474\n",
      "Epoch 94/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - loss: 56.6431 - val_loss: 3.1390\n",
      "Epoch 95/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 622us/step - loss: 52.7818 - val_loss: 4.5520\n",
      "Epoch 96/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 51.5483 - val_loss: 3.2860\n",
      "Epoch 97/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - loss: 57.3001 - val_loss: 4.2227\n",
      "Epoch 98/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615us/step - loss: 54.0990 - val_loss: 4.4777\n",
      "Epoch 99/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 608us/step - loss: 55.3424 - val_loss: 5.6960\n",
      "Epoch 100/100\n",
      "\u001b[1m105/105\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 55.6297 - val_loss: 3.6180\n",
      "Restoring model weights from the end of the best epoch: 94.\n",
      "Training finished...Loading the best model\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#save the best model\n",
    "checkpointer = ModelCheckpoint(filepath=\"dnn/best_weights1.keras\", verbose = 0, save_best_only = True) \n",
    "#optimizer definition (Adam)\n",
    "optimizer = Adam(learning_rate = 0.0001)\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    #build the network\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim = x.shape[1], activation = \"relu\"))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation = \"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation = \"relu\"))\n",
    "    model.add(Dense(1, activation = \"linear\"))\n",
    "   \n",
    "\n",
    "    #model compilation\n",
    "    model.compile(loss = 'mean_squared_error', optimizer = optimizer)\n",
    "    #early stopping\n",
    "    monitor = EarlyStopping(monitor = 'val_loss', patience = 7, restore_best_weights = True, verbose = 1)\n",
    "    #optimizer\n",
    "    optimizer = Adam(learning_rate = 0.0001)\n",
    "\n",
    "    #train model\n",
    "    history = model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 100, batch_size = 64, callbacks = [monitor, checkpointer], verbose = 1)\n",
    "print('Training finished...Loading the best model')  \n",
    "print()\n",
    "model.load_weights('dnn/best_weights1.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9a311ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m90/90\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step\n",
      "(2865, 1)\n",
      "Score (RMSE): 1.771726153723315\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred.shape)\n",
    "#rmse score\n",
    "score = np.sqrt(metrics.mean_squared_error(y_pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))\n",
    "chart_regression(y_pred.flatten(),y_test, sort = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
